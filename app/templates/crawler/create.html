{% extends "base.html" %}

{% block title %}Create Crawl Job - PersonaMap{% endblock %}

{% block content %}
<div class="row mt-4">
    <div class="col-12">
        <div class="d-flex justify-content-between align-items-center mb-4">
            <div>
                <h1><i class="bi bi-plus-circle"></i> Create New Crawl Job</h1>
                <p class="text-muted">Set up a new website crawling job</p>
            </div>
            <a href="{{ url_for('crawler.list_crawl_jobs') }}" class="btn btn-outline-secondary">
                <i class="bi bi-arrow-left"></i> Back to Crawl Jobs
            </a>
        </div>
    </div>
</div>

<div class="row">
    <div class="col-lg-8">
        <div class="card">
            <div class="card-body">
                <form method="POST">
                    <div class="mb-3">
                        <label for="name" class="form-label">Job Name</label>
                        <input type="text" class="form-control" id="name" name="name" 
                               value="{{ name or '' }}" required>
                        <div class="form-text">A descriptive name for this crawl job</div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="base_url" class="form-label">Base URL</label>
                        <input type="url" class="form-control" id="base_url" name="base_url" 
                               value="{{ base_url or '' }}" required 
                               placeholder="https://example.com">
                        <div class="form-text">The starting URL for the crawl (must include http:// or https://)</div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="max_pages" class="form-label">Maximum Pages</label>
                        <input type="number" class="form-control" id="max_pages" name="max_pages" 
                               value="{{ max_pages or 100 }}" min="1" max="10000" required>
                        <div class="form-text">Maximum number of pages to crawl (1-10,000)</div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="include_patterns" class="form-label">Include Patterns (Optional)</label>
                        <textarea class="form-control" id="include_patterns" name="include_patterns" 
                                  rows="3" placeholder="/blog/*&#10;/articles/*&#10;/news/*">{{ include_patterns or '' }}</textarea>
                        <div class="form-text">URL patterns to include (one per line). Leave empty to crawl all pages.</div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="exclude_patterns" class="form-label">Exclude Patterns (Optional)</label>
                        <textarea class="form-control" id="exclude_patterns" name="exclude_patterns" 
                                  rows="3" placeholder="/admin/*&#10;/login/*&#10;*.pdf">{{ exclude_patterns or '' }}</textarea>
                        <div class="form-text">URL patterns to exclude (one per line)</div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="crawl_mode" class="form-label">Crawl Mode</label>
                        <select class="form-select" id="crawl_mode" name="crawl_mode" required>
                            <option value="incremental" {{ 'selected' if crawl_mode == 'incremental' else '' }}>Incremental - Skip already crawled URLs</option>
                            <option value="overwrite" {{ 'selected' if crawl_mode == 'overwrite' else '' }}>Overwrite - Re-crawl and update existing URLs</option>
                        </select>
                        <div class="form-text">
                            <strong>Incremental:</strong> Skip URLs that have already been crawled (prevents duplicates)<br>
                            <strong>Overwrite:</strong> Re-crawl existing URLs and update their content and mappings
                        </div>
                    </div>
                    
                    <div class="mb-3">
                        <label for="schedule" class="form-label">Schedule (Optional)</label>
                        <select class="form-select" id="schedule" name="schedule">
                            <option value="">Manual only</option>
                            <option value="daily" {{ 'selected' if schedule == 'daily' else '' }}>Daily</option>
                            <option value="weekly" {{ 'selected' if schedule == 'weekly' else '' }}>Weekly</option>
                            <option value="monthly" {{ 'selected' if schedule == 'monthly' else '' }}>Monthly</option>
                        </select>
                        <div class="form-text">Automatic crawl schedule</div>
                    </div>
                    
                    <div class="d-flex justify-content-between">
                        <a href="{{ url_for('crawler.list_crawl_jobs') }}" class="btn btn-secondary">Cancel</a>
                        <button type="submit" class="btn btn-primary">
                            <i class="bi bi-check-circle"></i> Create Crawl Job
                        </button>
                    </div>
                </form>
            </div>
        </div>
    </div>
    
    <div class="col-lg-4">
        <div class="card">
            <div class="card-body">
                <h6 class="card-title">
                    <i class="bi bi-lightbulb"></i> Crawling Tips
                </h6>
                <ul class="list-unstyled">
                    <li class="mb-2">
                        <i class="bi bi-check-circle text-success"></i>
                        <strong>Start Small:</strong> Begin with 50-100 pages for testing
                    </li>
                    <li class="mb-2">
                        <i class="bi bi-check-circle text-success"></i>
                        <strong>Use Patterns:</strong> Include/exclude patterns help focus the crawl
                    </li>
                    <li class="mb-2">
                        <i class="bi bi-check-circle text-success"></i>
                        <strong>Respect Robots:</strong> The crawler follows robots.txt rules
                    </li>
                    <li class="mb-2">
                        <i class="bi bi-check-circle text-success"></i>
                        <strong>Monitor Progress:</strong> Check the job status regularly
                    </li>
                </ul>
            </div>
        </div>
        
        <div class="card mt-3">
            <div class="card-body">
                <h6 class="card-title">
                    <i class="bi bi-info-circle"></i> Pattern Examples
                </h6>
                <p class="small text-muted mb-2"><strong>Include:</strong></p>
                <code class="small">
                    /blog/*<br>
                    /articles/*<br>
                    /news/*
                </code>
                <p class="small text-muted mb-2 mt-3"><strong>Exclude:</strong></p>
                <code class="small">
                    /admin/*<br>
                    /login/*<br>
                    *.pdf<br>
                    *.jpg
                </code>
            </div>
        </div>
    </div>
</div>
{% endblock %}
